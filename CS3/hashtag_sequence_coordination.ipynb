{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3530934-93b6-42a7-aec5-7732320dced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4166a4a9-9b64-4096-9cbf-745016e42639",
   "metadata": {},
   "source": [
    "### The tweets file should only contain native tweets from the v1.1 Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efadc0-b21e-4c1a-b87f-eeddd129f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetid = []\n",
    "text = []\n",
    "hashtags = []\n",
    "userid = []\n",
    "created_at = []\n",
    "\n",
    "with gzip.open('tweets.json.gz', 'rb') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            tmp_json = json.loads(line)\n",
    "            for row in range(len(tmp_json)):\n",
    "                tweetid.append(tmp_json[row]['id_str'])\n",
    "                text.append(tmp_json[row]['text'])\n",
    "                userid.append(tmp_json[row]['user']['id_str'])\n",
    "                created_at.append(pd.to_datetime(tmp_json[row]['created_at']))\n",
    "                hashtags.append(tmp_json[row]['entities']['hashtags'])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "data = pd.DataFrame(tweetid, columns=['tweetid'])\n",
    "data['userid'] = userid\n",
    "data['created_at'] = created_at\n",
    "data['text'] = text\n",
    "data['hashtags'] = hashtags\n",
    "data.sort_values(by='created_at', inplace=True)\n",
    "\n",
    "# Extract users that meet the thresholds\n",
    "hashtag_seqs = dict()\n",
    "for user in data['userid'].unique():\n",
    "    tmp_str = []\n",
    "    count = 0\n",
    "    if len(data[data['userid'] == user].index) >= 5:\n",
    "        for index in data[data['userid'] == user].index:\n",
    "            if len(data.loc[index,'hashtags']) != 0:\n",
    "                count += 1\n",
    "                for hashtag in data.loc[index,'hashtags']:\n",
    "                    tmp_str.append(hashtag['text'])\n",
    "        if (len(set(tmp_str)) >= 5) & (count >= 5):\n",
    "            tmp_str = \"\".join(tmp_str)\n",
    "            if tmp_str in hashtag_seqs.keys():\n",
    "                hashtag_seqs[tmp_str].append(user)\n",
    "            else:\n",
    "                hashtag_seqs[tmp_str] = [user]\n",
    "\n",
    "# Build an undirect network of users that met the above thresholds and\n",
    "# have the same hashtag sequences\n",
    "G = nx.Graph()\n",
    "for key in hashtag_seqs.keys():\n",
    "    if len(hashtag_seqs[key]) > 1:\n",
    "        for comb in list(combinations(hashtag_seqs[key], 2)):\n",
    "            nx.add_edge(comb[0], comb[1])\n",
    "\n",
    "nx.write_gexf(G,'hashtag_coordination_graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e755a-2ea3-48df-be81-39689f53fff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
